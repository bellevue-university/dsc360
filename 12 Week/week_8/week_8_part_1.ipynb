{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Week 8 – Document Similarity and Clustering\n",
    "## Analyzing Term Similarity - Starting on page 459"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Terms:\n ['Believe', 'beleive', 'bargain', 'Elephant'] \n\nTerm vectors:\n             0    1    2    3    4    5    6      7\nBelieve    98  101  108  105  101  118  101    NaN\nbeleive    98  101  108  101  105  118  101    NaN\nbargain    98   97  114  103   97  105  110    NaN\nElephant  101  108  101  112  104   97  110  116.0 \n\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import itemfreq\n",
    "\n",
    "def vectorize_terms(terms):\n",
    "    terms = [term.lower() for term in terms]\n",
    "    terms = [np.array(list(term)) for term in terms]\n",
    "    terms = [np.array([ord(char) for char in term]) \n",
    "                for term in terms]\n",
    "    return terms\n",
    "\n",
    "root = 'Believe'\n",
    "term1 = 'beleive'\n",
    "term2 = 'bargain'\n",
    "term3 = 'Elephant'\n",
    "\n",
    "terms = [root, term1, term2, term3]\n",
    "print('Terms:\\n', terms, '\\n')\n",
    "\n",
    "# Character vectorization\n",
    "term_vectors = vectorize_terms(terms)\n",
    "\n",
    "# show vector representations\n",
    "vec_df = pd.DataFrame(term_vectors, index=terms)\n",
    "print('Term vectors:\\n', vec_df, '\\n')\n",
    "\n",
    "root_term = root\n",
    "other_terms = [term1, term2, term3]\n",
    "\n",
    "root_term_vec = vec_df[vec_df.index == root_term].dropna(axis=1).values[0]\n",
    "other_term_vecs = [vec_df[vec_df.index == term].dropna(axis=1).values[0]\n",
    "                   for term in other_terms]"
   ]
  },
  {
   "source": [
    "## Hamming Distance starting on page 461"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hamming Distance:\nHamming distance between root: Believe and term: beleive is 2\nHamming distance between root: Believe and term: bargain is 6\nAn error occurred:The vectors must have equal lengths.\nNormalized Hamming distance between root: Believe and term: beleive is 0.29\nNormalized Hamming distance between root: Believe and term: bargain is 0.86\nAn error occurred:The vectors must have equal lengths.\n"
     ]
    }
   ],
   "source": [
    "print('Hamming Distance:')\n",
    "def hamming_distance(u, v, norm=False):\n",
    "    if u.shape != v.shape:\n",
    "        raise ValueError('The vectors must have equal lengths.')\n",
    "    return (u != v).sum() if not norm else (u != v).mean()\n",
    "\n",
    "# compute Hamming distance\n",
    "for term, term_vector in zip(other_terms, other_term_vecs):\n",
    "    try:\n",
    "        print('Hamming distance between root: {} and term: {} is {}'.\n",
    "              format(root_term, term, hamming_distance(root_term_vec, term_vector,\n",
    "                                                       norm=False)))\n",
    "    except ValueError as ve:\n",
    "        print('An error occurred:' + str(ve))\n",
    "        continue\n",
    "\n",
    "# computer normalized Hamming distance - I caught the exception unlike the book\n",
    "for term, term_vector in zip(other_terms, other_term_vecs):\n",
    "    try:\n",
    "        print('Normalized Hamming distance between root: {} and term: {} is {}'\n",
    "              .format(root_term, term,round(hamming_distance(root_term_vec,\n",
    "                                                             term_vector, norm=True), 2)))\n",
    "    except ValueError as ve:\n",
    "        print('An error occurred:' + str(ve))\n",
    "        continue"
   ]
  },
  {
   "source": [
    "## Manhattan Distance - Page 463"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nManhattan Distance:\nAn error occurred:The vectors must have equal lengths.\nAn error occurred:The vectors must have equal lengths.\nAn error occurred:The vectors must have equal lengths.\nNormalized Manhattan distance between root: Believe and term: beleive is 1.14\nNormalized Manhattan distance between root: Believe and term: bargain is 5.43\nAn error occurred:The vectors must have equal lengths.\n"
     ]
    }
   ],
   "source": [
    "print('\\nManhattan Distance:')\n",
    "def manhattan_distance(u, v, norm=False):\n",
    "    if u.shape != v.shape:\n",
    "        raise ValueError('The vectors must have equal lengths.')\n",
    "    return abs(u - v).sum() if not norm else abs(u - v).mean()\n",
    "\n",
    "# compute Manhattan distance\n",
    "for term, vector_term in zip(other_terms, other_term_vecs):\n",
    "    try:\n",
    "        print('Manhattan distance between root: {} and term: {} is {}'\n",
    "              .format(root_term, term, manhattan_distance(root_term_vec,\n",
    "                                                          term_vector, norm=False)))\n",
    "    except ValueError as ve:\n",
    "        print('An error occurred:' + str(ve))\n",
    "        continue\n",
    "\n",
    "# computer normalized Manhattan distance\n",
    "for term, term_vector in zip(other_terms, other_term_vecs):\n",
    "    try:\n",
    "        print('Normalized Manhattan distance between root: {} and term: {} is {}'\n",
    "              .format(root_term, term, round(manhattan_distance(root_term_vec, term_vector,\n",
    "                                                                norm=True), 2)))\n",
    "    except ValueError as ve:\n",
    "        print('An error occurred:' + str(ve))\n",
    "        continue"
   ]
  },
  {
   "source": [
    "## Euclidean Distance starting on page 463"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nEuclidean Distance:\nEuclidean distance between root: Believe and term: beleive is 5.66\nEuclidean distance between root: Believe and term: bargain is 17.94\nAn error occurred:The vectors must have equal lengths.\n"
     ]
    }
   ],
   "source": [
    "print('\\nEuclidean Distance:')\n",
    "def euclidean_distance(u,v):\n",
    "    if u.shape != v.shape:\n",
    "        raise ValueError('The vectors must have equal lengths.')\n",
    "    distance = np.sqrt(np.sum(np.square(u - v)))\n",
    "    return distance\n",
    "\n",
    "# compute Euclidean distance\n",
    "for term, term_vector in zip(other_terms, other_term_vecs):\n",
    "    try:\n",
    "        print('Euclidean distance between root: {} and term: {} is {}'\n",
    "              .format(root_term, term, round(euclidean_distance(root_term_vec,\n",
    "                                                                term_vector), 2)))\n",
    "    except ValueError as ve:\n",
    "        print('An error occurred:' + str(ve))\n",
    "        continue"
   ]
  },
  {
   "source": [
    "## Levenshtein Edit Distance starting on page 467"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nLevenshtein Edit Distance\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'lower'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-24a286940be2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;31m# Computer Levenshtein distance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mterm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mterm_vector\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother_terms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother_term_vecs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0medit_d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medit_m\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlevenshtein_edit_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_term_vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mterm_vector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     print('Computing distance between root: {} and term: {}'.format(root_term,\n\u001b[0;32m     45\u001b[0m                                                                     term))\n",
      "\u001b[1;32m<ipython-input-9-24a286940be2>\u001b[0m in \u001b[0;36mlevenshtein_edit_distance\u001b[1;34m(u, v)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlevenshtein_edit_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# convert to lower case\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# base cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "print('\\nLevenshtein Edit Distance')\n",
    "import copy\n",
    "def levenshtein_edit_distance(u, v):\n",
    "    # convert to lower case\n",
    "    u = u.lower()\n",
    "    v = v.lower()\n",
    "    # base cases\n",
    "    if u == v: return 0\n",
    "    elif len(u) == 0: return len(v)\n",
    "    elif len(v) == 0: return len(u)\n",
    "    # initialize edit distance matrix\n",
    "    edit_matrix = []\n",
    "    # initialize two distance matrices \n",
    "    du = [0] * (len(v) + 1)\n",
    "    dv = [0] * (len(v) + 1)\n",
    "    # du: the previous row of edit distances\n",
    "    for i in range(len(du)):\n",
    "        du[i] = i\n",
    "    # dv : the current row of edit distances    \n",
    "    for i in range(len(u)):\n",
    "        dv[0] = i + 1\n",
    "        # compute cost as per algorithm\n",
    "        for j in range(len(v)):\n",
    "            cost = 0 if u[i] == v[j] else 1\n",
    "            dv[j + 1] = min(dv[j] + 1, du[j + 1] + 1, du[j] + cost)\n",
    "        # assign dv to du for next iteration\n",
    "        for j in range(len(du)):\n",
    "            du[j] = dv[j]\n",
    "        # copy dv to the edit matrix\n",
    "        edit_matrix.append(copy.copy(dv))\n",
    "    # compute the final edit distance and edit matrix    \n",
    "    distance = dv[len(v)]\n",
    "    edit_matrix = np.array(edit_matrix)\n",
    "    edit_matrix = edit_matrix.T\n",
    "    edit_matrix = edit_matrix[1:,]\n",
    "    edit_matrix = pd.DataFrame(data=edit_matrix,\n",
    "                               index=list(v),\n",
    "                               columns=list(u))\n",
    "    return distance, edit_matrix\n",
    "\n",
    "# Computer Levenshtein distance\n",
    "for term, term_vector in zip(other_terms, other_term_vecs):\n",
    "    edit_d, edit_m = levenshtein_edit_distance(root_term_vec, term_vector)\n",
    "    print('Computing distance between root: {} and term: {}'.format(root_term,\n",
    "                                                                    term))\n",
    "    print('Levenshtein edit distance is {}'.format(edit_d))\n",
    "    print('The complete edit distance matrix is depicted below')\n",
    "    print(edit_m)\n",
    "    print('-'*30)\n",
    "\n",
    "print('\\n')\n"
   ]
  },
  {
   "source": [
    "## Cosine Distance and Similarity starting on page 473"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nCosine Distance:\nBag of characters vectors:\n           a  b  e  g  h  i  l  n  p  r  t  v\nBelieve   0  1  3  0  0  1  1  0  0  0  0  1\nbeleive   0  1  3  0  0  1  1  0  0  0  0  1\nbargain   2  1  0  1  0  1  0  1  0  1  0  0\nElephant  1  0  2  0  1  0  1  1  1  0  1  0\n\nCompute Cosine Distance:\nAnalyzing similarity between root: Believe and term: beleive\nCosine distance  is -0.0\nCosine similarity  is 1.0\n----------------------------------------\nAnalyzing similarity between root: Believe and term: bargain\nCosine distance  is 0.82\nCosine similarity  is 0.18000000000000005\n----------------------------------------\nAnalyzing similarity between root: Believe and term: Elephant\nCosine distance  is 0.39\nCosine similarity  is 0.61\n----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('\\nCosine Distance:')\n",
    "def boc_term_vectors(word_list):\n",
    "    word_list = [word.lower() for word in word_list]\n",
    "    unique_chars = np.unique(np.hstack([list(word)\n",
    "                                        for word in word_list]))\n",
    "    word_list_term_counts = [{char: count for char, count in np.stack(\n",
    "        np.unique(list(word), return_counts=True), axis=1)} for word in word_list]\n",
    "\n",
    "    boc_vectors = [np.array([int(word_term_counts.get(char, 0))\n",
    "                             for char in unique_chars])\n",
    "                   for word_term_counts in word_list_term_counts]\n",
    "    return list(unique_chars), boc_vectors\n",
    "\n",
    "feature_names, feature_vectors = boc_term_vectors(terms)\n",
    "boc_df = pd.DataFrame(feature_vectors, columns=feature_names, index=terms)\n",
    "print('Bag of characters vectors:\\n', boc_df)\n",
    "\n",
    "def cosine_distance(u, v):\n",
    "    distance = 1.0 - (np.dot(u, v) / \n",
    "                        (np.sqrt(sum(np.square(u))) * np.sqrt(sum(np.square(v)))))\n",
    "    return distance\n",
    "\n",
    "root_term_boc = boc_df[vec_df.index == root_term].values[0]\n",
    "other_term_bocs = [boc_df[vec_df.index == term].values[0]\n",
    "                   for term in other_terms]\n",
    "\n",
    "# Compute Cosine Distance\n",
    "print('\\nCompute Cosine Distance:')\n",
    "for term, boc_term in zip(other_terms, other_term_bocs):\n",
    "    print('Analyzing similarity between root: {} and term: {}'.format(root_term, term))\n",
    "    distance = round(cosine_distance(root_term_boc, boc_term), 2)\n",
    "    similarity = 1 - distance                                                           \n",
    "    print('Cosine distance  is {}'.format(distance))\n",
    "    print('Cosine similarity  is {}'.format(similarity))\n",
    "    print('-'*40)"
   ]
  },
  {
   "source": [
    "## Building a Movie Recommender - starting on page 477"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4803 entries, 0 to 4802\n",
      "Data columns (total 20 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   budget                4803 non-null   int64  \n",
      " 1   genres                4803 non-null   object \n",
      " 2   homepage              1712 non-null   object \n",
      " 3   id                    4803 non-null   int64  \n",
      " 4   keywords              4803 non-null   object \n",
      " 5   original_language     4803 non-null   object \n",
      " 6   original_title        4803 non-null   object \n",
      " 7   overview              4800 non-null   object \n",
      " 8   popularity            4803 non-null   float64\n",
      " 9   production_companies  4803 non-null   object \n",
      " 10  production_countries  4803 non-null   object \n",
      " 11  release_date          4802 non-null   object \n",
      " 12  revenue               4803 non-null   int64  \n",
      " 13  runtime               4801 non-null   float64\n",
      " 14  spoken_languages      4803 non-null   object \n",
      " 15  status                4803 non-null   object \n",
      " 16  tagline               3959 non-null   object \n",
      " 17  title                 4803 non-null   object \n",
      " 18  vote_average          4803 non-null   float64\n",
      " 19  vote_count            4803 non-null   int64  \n",
      "dtypes: float64(3), int64(4), object(13)\n",
      "memory usage: 750.6+ KB\n",
      "Columns\n",
      " Index(['budget', 'genres', 'homepage', 'id', 'keywords', 'original_language',\n",
      "       'original_title', 'overview', 'popularity', 'production_companies',\n",
      "       'production_countries', 'release_date', 'revenue', 'runtime',\n",
      "       'spoken_languages', 'status', 'tagline', 'title', 'vote_average',\n",
      "       'vote_count'],\n",
      "      dtype='object') \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4800 entries, 0 to 4802\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   title        4800 non-null   object \n",
      " 1   tagline      4800 non-null   object \n",
      " 2   overview     4800 non-null   object \n",
      " 3   genres       4800 non-null   object \n",
      " 4   popularity   4800 non-null   float64\n",
      " 5   description  4800 non-null   object \n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 262.5+ KB\n",
      "\n",
      "Simplified DF:\n",
      "                                       title  \\\n",
      "0                                    Avatar   \n",
      "1  Pirates of the Caribbean: At World's End   \n",
      "2                                   Spectre   \n",
      "3                     The Dark Knight Rises   \n",
      "4                               John Carter   \n",
      "\n",
      "                                          tagline  \\\n",
      "0                     Enter the World of Pandora.   \n",
      "1  At the end of the world, the adventure begins.   \n",
      "2                           A Plan No One Escapes   \n",
      "3                                 The Legend Ends   \n",
      "4            Lost in our world, found in another.   \n",
      "\n",
      "                                            overview  \\\n",
      "0  In the 22nd century, a paraplegic Marine is di...   \n",
      "1  Captain Barbossa, long believed to be dead, ha...   \n",
      "2  A cryptic message from Bond’s past sends him o...   \n",
      "3  Following the death of District Attorney Harve...   \n",
      "4  John Carter is a war-weary, former military ca...   \n",
      "\n",
      "                                              genres  popularity  \\\n",
      "0  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...  150.437577   \n",
      "1  [{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...  139.082615   \n",
      "2  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...  107.376788   \n",
      "3  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...  112.312950   \n",
      "4  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   43.926995   \n",
      "\n",
      "                                         description  \n",
      "0  Enter the World of Pandora. In the 22nd centur...  \n",
      "1  At the end of the world, the adventure begins....  \n",
      "2  A Plan No One Escapes A cryptic message from B...  \n",
      "3  The Legend Ends Following the death of Distric...  \n",
      "4  Lost in our world, found in another. John Cart...   \n",
      "\n",
      "Length of normalized corpus: 4800 \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4800 entries, 0 to 4802\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   title        4800 non-null   object \n",
      " 1   tagline      4800 non-null   object \n",
      " 2   overview     4800 non-null   object \n",
      " 3   genres       4800 non-null   object \n",
      " 4   popularity   4800 non-null   float64\n",
      " 5   description  4800 non-null   object \n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 262.5+ KB\n",
      "None \n",
      "\n",
      "TFIDF matrix shape:\n",
      " (4800, 20667) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/tmdb_5000_movies.csv')\n",
    "df.info()\n",
    "print('Columns\\n', df.columns, '\\n')\n",
    "\n",
    "df = df[['title', 'tagline', 'overview', 'genres', 'popularity']]\n",
    "df.tagline.fillna('', inplace=True)\n",
    "df['description'] = df['tagline'].map(str) + ' ' + df['overview']\n",
    "df.dropna(inplace=True)\n",
    "df.info()\n",
    "print('\\nSimplified DF:\\n', df.head(), '\\n')\n",
    "\n",
    "# Text preprocessing - starting on page 480\n",
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # lower case and remove special chars/whitespace\n",
    "    doc = re.sub('[^a-zA-Z0-9\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    # tokenize doc\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "normalize_corpus = np.vectorize(normalize_document)\n",
    "\n",
    "df['description'] = \\\n",
    "        df['description'].apply(lambda x: normalize_corpus(x))\n",
    "norm_corpus = df['description']\n",
    "print('Length of normalized corpus:', len(norm_corpus), '\\n')\n",
    "print(df.info(), '\\n')\n",
    "\n",
    "# Save this updated corpus df\n",
    "df.to_csv('./data/norm_corpus.csv')\n",
    "\n",
    "# Extract TF-IDF Features - page 481\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf = TfidfVectorizer(ngram_range=(1, 2), min_df=2)\n",
    "tfidf_matrix = tf.fit_transform(norm_corpus)\n",
    "print('TFIDF matrix shape:\\n', tfidf_matrix.shape, '\\n')"
   ]
  },
  {
   "source": [
    "### Cosine similarity and pairwise doc similarity page 482"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Document similarity df:\n        0         1         2         3         4         5         6     \\\n0  1.000000  0.010701  0.000000  0.019030  0.028687  0.024901  0.000000   \n1  0.010701  1.000000  0.011891  0.000000  0.041623  0.000000  0.014564   \n2  0.000000  0.011891  1.000000  0.000000  0.000000  0.000000  0.000000   \n3  0.019030  0.000000  0.000000  1.000000  0.008793  0.000000  0.015976   \n4  0.028687  0.041623  0.000000  0.008793  1.000000  0.000000  0.022912   \n\n       7         8         9     ...      4790  4791      4792      4793  \\\n0  0.026516  0.000000  0.007420  ...  0.009702   0.0  0.023336  0.033549   \n1  0.027122  0.034688  0.007614  ...  0.009956   0.0  0.004818  0.000000   \n2  0.022242  0.015854  0.004891  ...  0.042617   0.0  0.000000  0.000000   \n3  0.023172  0.027452  0.073610  ...  0.000000   0.0  0.009667  0.000000   \n4  0.028676  0.000000  0.023538  ...  0.014800   0.0  0.000000  0.000000   \n\n       4794      4795  4796      4797      4798      4799  \n0  0.000000  0.000000   0.0  0.006892  0.000000  0.000000  \n1  0.000000  0.012593   0.0  0.022391  0.013724  0.000000  \n2  0.016519  0.000000   0.0  0.011682  0.000000  0.004000  \n3  0.000000  0.000000   0.0  0.028354  0.021785  0.027735  \n4  0.000000  0.010760   0.0  0.010514  0.000000  0.000000  \n\n[5 rows x 4800 columns] \n\nMovies list:\n ['Avatar' \"Pirates of the Caribbean: At World's End\" 'Spectre' ...\n 'Signed, Sealed, Delivered' 'Shanghai Calling' 'My Date with Drew'] (4800,) \n\nMovie like Minions:\n 546 \n\nMovie similarities, like Minions:\n [0.0104544  0.01072835 0.         ... 0.00690954 0.         0.        ] \n\nSimilar movie indices like Minions:\n [506 614 241 813 154] \n\nSimilar movies to Minions:\n ['Despicable Me 2' 'Despicable Me'\n 'Teenage Mutant Ninja Turtles: Out of the Shadows' 'Superman'\n 'Rise of the Guardians'] \n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "doc_sim = cosine_similarity(tfidf_matrix)\n",
    "doc_sim_df = pd.DataFrame(doc_sim)\n",
    "print('Document similarity df:\\n', doc_sim_df.head(),'\\n')\n",
    "\n",
    "# Movie list page 482\n",
    "movies_list = df['title'].values\n",
    "print('Movies list:\\n', movies_list, movies_list.shape, '\\n')\n",
    "\n",
    "# Find top similar movies for a sample movie page 483\n",
    "movie_idx = np.where(movies_list == 'Minions')[0][0]\n",
    "print('Movie like Minions:\\n', movie_idx, '\\n')\n",
    "\n",
    "# Movie similarities\n",
    "movie_similarities = doc_sim_df.iloc[movie_idx].values\n",
    "print('Movie similarities, like Minions:\\n', movie_similarities, '\\n')\n",
    "\n",
    "# Top five similar movie IDs\n",
    "similar_movie_idxs = np.argsort(-movie_similarities)[1:6]\n",
    "print('Similar movie indices like Minions:\\n', similar_movie_idxs, '\\n')\n",
    "\n",
    "# Get top five similar movies page 484\n",
    "similar_movies = movies_list[similar_movie_idxs]\n",
    "print('Similar movies to Minions:\\n', similar_movies, '\\n')"
   ]
  },
  {
   "source": [
    "### Build a movie recommender page 484"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Popular movies:\n                            title  \\\n546                      Minions   \n95                  Interstellar   \n788                     Deadpool   \n94       Guardians of the Galaxy   \n127           Mad Max: Fury Road   \n...                          ...   \n4625            Midnight Cabaret   \n4118      Hum To Mohabbat Karega   \n4727                Penitentiary   \n3361                  Alien Zone   \n4553  America Is Still the Place   \n\n                                                tagline  \\\n546        Before Gru, they had a history of bad bosses   \n95    Mankind was born on Earth. It was never meant ...   \n788             Witness the beginning of a happy ending   \n94                          All heroes start somewhere.   \n127                                  What a Lovely Day.   \n...                                                 ...   \n4625                The hot spot where Satan's waitin'.   \n4118                                                      \n4727  There's only one way out, and 100 fools stand ...   \n3361                        Don't you dare go in there!   \n4553                                                      \n\n                                               overview  \\\n546   Minions Stuart, Kevin and Bob are recruited by...   \n95    Interstellar chronicles the adventures of a gr...   \n788   Deadpool tells the origin story of former Spec...   \n94    Light years from Earth, 26 years after being a...   \n127   An apocalyptic story set in the furthest reach...   \n...                                                 ...   \n4625  A Broadway producer puts on a play with a Devi...   \n4118  Raju, a waiter, is in love with the famous TV ...   \n4727  A hitchhiker named Martel Gordone gets in a fi...   \n3361  A man who is having an affair with a married w...   \n4553  1971 post civil rights San Francisco seemed li...   \n\n                                                 genres  popularity  \\\n546   [{\"id\": 10751, \"name\": \"Family\"}, {\"id\": 16, \"...  875.581305   \n95    [{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 18, \"...  724.247784   \n788   [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...  514.569956   \n94    [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 878, \"na...  481.098624   \n127   [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...  434.278564   \n...                                                 ...         ...   \n4625                     [{\"id\": 27, \"name\": \"Horror\"}]    0.001389   \n4118                                                 []    0.001186   \n4727  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 18, \"nam...    0.001117   \n3361  [{\"id\": 27, \"name\": \"Horror\"}, {\"id\": 28, \"nam...    0.000372   \n4553                                                 []    0.000000   \n\n                                            description  \n546   gru history bad bosses minions stuart kevin bo...  \n95    mankind born earth never meant die interstella...  \n788   witness beginning happy ending deadpool tells ...  \n94    heroes start somewhere light years earth 26 ye...  \n127   lovely day apocalyptic story set furthest reac...  \n...                                                 ...  \n4625  hot spot satans waitin broadway producer puts ...  \n4118  raju waiter love famous tv reporter greeta kap...  \n4727  theres one way 100 fools stand way hitchhiker ...  \n3361  dont dare go man affair married woman dropped ...  \n4553  1971 post civil rights san francisco seemed li...  \n\n[4800 rows x 6 columns] \n\nMovie: Minions\nTop 5 recommended movies: ['Despicable Me 2' 'Despicable Me'\n 'Teenage Mutant Ninja Turtles: Out of the Shadows' 'Superman'\n 'Rise of the Guardians'] \n\nMovie: Interstellar\nTop 5 recommended movies: ['Gattaca' 'Space Pirate Captain Harlock' 'Space Cowboys'\n 'Starship Troopers' 'Final Destination 2'] \n\nMovie: Deadpool\nTop 5 recommended movies: ['Silent Trigger' 'Underworld: Evolution' 'Bronson' 'Shaft' 'Don Jon'] \n\nMovie: Guardians of the Galaxy\nTop 5 recommended movies: ['Chasing Mavericks' 'E.T. the Extra-Terrestrial' 'American Sniper'\n 'The Amazing Spider-Man 2' 'Hoop Dreams'] \n\nMovie: Mad Max: Fury Road\nTop 5 recommended movies: ['The 6th Day' 'Star Trek Beyond' 'Kites' 'The Orphanage'\n 'The Water Diviner'] \n\n"
     ]
    }
   ],
   "source": [
    "def movie_recommender(movie_title, movies=movies_list, doc_sims=doc_sim_df):\n",
    "    # find movie id\n",
    "    movie_idx = np.where(movies == movie_title)[0][0]\n",
    "    # get movie similarities\n",
    "    movie_similarities = doc_sims.iloc[movie_idx].values\n",
    "    # get top 5 similar movie ids\n",
    "    similar_movie_idxs = np.argsort(-movie_similarities)[1:6]\n",
    "    # get top 5 movies\n",
    "    similar_movies = movies[similar_movie_idxs]\n",
    "    # return the top 5 movies\n",
    "    return similar_movies\n",
    "\n",
    "popular_movies = df.sort_values(by='popularity', ascending=False)\n",
    "print('Popular movies:\\n', popular_movies, '\\n')\n",
    "\n",
    "# Just 5 movies\n",
    "for movie in popular_movies['title'][0:5]:\n",
    "    print('Movie:', movie)\n",
    "    print('Top 5 recommended movies:', movie_recommender(movie_title=movie), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}